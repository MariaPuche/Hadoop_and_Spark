# Padron_Madrid

Usandos los datos de Padrón Madrid que se encuentran en la cartpeta datos, se van a realizar diferentes tareas utilizando los ecosistemas de Hadoop más populares. Para poder llevarlos a cabo, se va a trabajar con la imagen de cloudera, creando un contenedor de esta en docker. Para poder trabajar con la interfaz de hue, se configura con el puerto 8888.

El repositorio se va a encontrar formado por:
- Una carpeta *datos* donde se encuentra ubicado el fichero csv que se va a utilizar a lo largo de toda la práctica.
- Una caperta *ejercicos* dividida a su vez en:
    - Hive -> Formada por los ejercicios que se desarrollan en este ecosistema: creación de tablas en formato parquet y texto, consultas y, por último, particiones de las tablas.
    - Impala ->
    - HDFS --> Donde se realizan ejercicios para ver las diferencias entre las tablas externas y gestionas, incluyendo distintos comandos propios de HDFS.
    - Spark --> Se aplican los conocimientos sobre el manejo de DataFrames y tablas de Hive a través de Spark.sql.

- Un archivo *Una pincelada de Hive e Impala* que describe las principales características de Hive e Impala y las diferencias entre ellas.

