# Hadoop_and_Spark

Este repositorio va a estar formado por mis avances personales sobre **Hadoop y Spark** que voy adquiriendo a lo largo de mis pr치cticas empresariales en Bosonit. La estructura de este es:
- Fundamentos Big Data -> Esta carpeta engloba todos los ejercicios correspondiente a un curso de Big Data, en el se incluye material relacionado con los distintos ecosistemas de Hadoop (**Hive, Impala, Sqoop, Flume y Pig**) y comandos b치sicos sobre el almacenamiento **HDFS**.
- Web Sever Logs Analysis -> El caso de estudio que se lleva a cabo es analizar los web server logs de la NASA con **Scala** y **Python**. Para el primero, se ha creado un proyecto con el nombre *Nasa* en **IntelliJ** y se han subido los archivos. Sin embargo, para python, se ha utilizado los notebooks de **Databricks**.
- Padron Madrid -> El caso de estudio consiste en analizar los datos del padron de Madrid utilizando diferentes ecosistemas de Hadoop, como son **Hive, Impala o HDFS**. Adem치s, se van a realizar ejercicios con **Spark**. Todo esto se realizar치 en una imagen de cloudera montada en un contenedor con **Docker**.
