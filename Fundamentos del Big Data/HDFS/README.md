# HDFS

## ¿Qué es?
Es el componente principal del ecosistema Hadoop que permite almacenar datasets masivos don tipos de datos estructurados, semi-estructurados y no estructurados. 

Esta optimicado para almacenar grandes cantidades de datos y mantener varias copias para garantizar una alta disponibilidad y la tolerancia a fallos, por ende, se considera el almacenamiento Big Data por excelencia. 

HDFS se encarga de almacenar los datos en varios nodos manteniendo sus metadatos, aumentando la velocidad de procesamiento, el paralelismos en las operaciones y permite la replicación de los datos.

